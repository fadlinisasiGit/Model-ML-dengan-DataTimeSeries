# -*- coding: utf-8 -*-
"""ProyekKedua_KelasMenengah.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTb7KgrGaNtYGLl5giIzLCLbahz_31Rl

Nama : Muhammad Fadli Ramadhan

gmail : fadlinisasileader@gmail.com

Proyek Kedua : Membuat Model Machine Learning dengan Data Time Series

Selasa, 14 September 2021
"""

# import library
import pandas as pd
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import LSTM,Dense,Bidirectional,Dropout
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential

# upload dan read dataset
df = pd.read_csv('GlobalLandTemperatures_GlobalLandTemperaturesByMajorCity.csv',
                 encoding='unicode_escape')
df

# Menghilangkan kolom yang tidak diperlukan
df.drop(['City', 'Latitude', 'Longitude'], axis=1, inplace=True)
display(df)

# meminimalisasi data ke data tahun 1991 - 1999
df['dt'] = pd.to_datetime(df['dt'])
get_data = (df['dt'] > '1991-01-01') & (df['dt'] <= '1999-12-01')
df.loc[get_data]
df = df.loc[get_data]
display(df)

# Mengambil data Negara China saja
df = df.loc[df['Country'].isin(['China'])]
display(df)

# Cek missing value
df.isnull().sum()

# Membuat plot masing masing kolom dan Average Temperaturepada tiap waktu
df_plot = df
df_plot[df_plot.columns.to_list()].plot(subplots=True, figsize=(20,15))

plt.show()

dates = df['dt'].values
temp = df['AverageTemperature'].values

dates = np.array(dates)
temp = np.array(temp)

plt.figure(figsize=(20,5))
plt.plot(dates, temp)

plt.title('Average Temperature', fontsize=22)
plt.ylabel('Temperature')
plt.xlabel('Datetime')

# split data dengan Validation set sebesar 20% dari total dataset
x_train, x_valid, y_train, y_valid = train_test_split(temp, dates, test_size=0.2,
                                                      shuffle = False)
print('Total Data Train : ', len(x_train))
print('Total Data Validation : ', len(x_valid))

# mengubah data ke dalam bentuk batch
def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=-1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift=1, drop_remainder = True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

# Membuat model Sequential
tf.keras.backend.set_floatx('float64')

train_set = windowed_dataset(x_train, window_size=64, batch_size=200,
                             shuffle_buffer=1000)
val_set = windowed_dataset(x_valid, window_size=64, batch_size=200,
                           shuffle_buffer=1000)

model = Sequential([
        Bidirectional(LSTM(60, return_sequences=True)),
        Bidirectional(LSTM(60)),
        Dense(30, activation='relu'),
        Dense(10, activation='relu'),
        Dense(1)
])

# nilai MAE
mae = (df['AverageTemperature'].max() - df['AverageTemperature'].min()) * 10/100
print (mae)

# Fungsi Callbacks
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < mae and logs.get('val_name') < mae):
      print("\nMAE dari model fit < nilai mae ")
      self.model.stop_training = True
callbacks = myCallback()

# Learning Rate pada Optimizer
optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=['mae'])

#Penggunaan Fungsi Callbacks
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')< mae and logs.get('val_mae')< mae ):
      print("\nMAE dari model fit < mae ")
      self.model.stop_training = True
callbacks = myCallback()

# Penggunaan Learning Rate pada Optimizer
optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
history = model.fit(train_set, epochs=100, validation_data = val_set,
                    callbacks=[callbacks])

# Plot akurasi dan loss model

# Plot akurasi
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Akurasi Model')
plt.ylabel('Mae')
plt.xlabel('epoch')
plt.show()

# Plot loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()